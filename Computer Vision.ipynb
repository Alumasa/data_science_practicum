{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some data\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('/datasets/train_data_n.csv')\n",
    "features = data.drop('target', axis=1)\n",
    "target = data['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in sklearn\n",
    "# import from sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# create the model\n",
    "model = LinearRegression()\n",
    "\n",
    "# train the model\n",
    "model.fit(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in keras\n",
    "# import Keras\n",
    "from tensorflow import keras\n",
    "\n",
    "# create the model\n",
    "model = keras.models.Sequential()\n",
    "# indicate how the neural network is arranged\n",
    "model.add(keras.layers.Dense(units=1, input_dim=features.shape[1]))\n",
    "# indicate how the neural network is trained\n",
    "model.compile(loss='mean_squared_error', optimizer='sgd')\n",
    "\n",
    "# train the model\n",
    "model.fit(features, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's set the model class to Sequential. \n",
    "- This class is used for models with sequential layers. Layer is a set of neurons that share the same input and output.\n",
    "\n",
    "- The keras.layers.Dense() command creates one layer of neurons. \n",
    "- \"Dense\" means that every input will be connected to every neuron, or output. \n",
    "- The units parameter sets the number of neurons in the layer, and input_dim sets the number of inputs in the layer. \n",
    "- Note that this parameter doesn't take the bias into account.\n",
    "- To add the fully connected layer to the model, call the model.add() method:\n",
    "- `model.compile` - It prepares the model for training. \n",
    "- Specify MSE as the regression task loss function for the loss parameter. \n",
    "-Set the gradient descent method for the optimizer='sgd' parameter. Remember, we'll be training neural networks using SGD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Layers where all inputs are connected to all neurons are called **fully connected layers**.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`keras.layers.Dense(units=2, input_dim=3)` - two neurons and three inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "\n",
    "data = pd.read_csv('/datasets/train_data_n.csv')\n",
    "features = data.drop('target', axis=1)\n",
    "target = data['target']\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(units=1, input_dim=features.shape[1]))\n",
    "model.compile(loss='mean_squared_error', optimizer='sgd')\n",
    "model.fit(features, target, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#epochs = how many times has our data passed through the algorithm) to get the MSE to be less than 6.55.\n",
    "model.fit(features, target, verbose=2, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the loss function value for the validation set.\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "\n",
    "data_train = pd.read_csv('/datasets/train_data_n.csv')\n",
    "features_train = data_train.drop('target', axis=1)\n",
    "target_train = data_train['target']\n",
    "\n",
    "data_valid = pd.read_csv('/datasets/test_data_n.csv')\n",
    "features_valid = data_valid.drop('target', axis=1)\n",
    "target_valid = data_valid['target']\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(units=1, input_dim=features_train.shape[1]))\n",
    "model.compile(loss='mean_squared_error', optimizer='sgd')\n",
    "model.fit(features_train, target_train, validation_data=(features_valid, target_valid), epochs=5, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply the activation function to the fully connected layer:\n",
    "keras.layers.Dense(units=1, input_dim=features_train.shape[1], activation='sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change the loss function from MSE to binary_crossentropy;\n",
    "model.compile(loss='binary_crossentropy', optimizer='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "\n",
    "df = pd.read_csv('/datasets/train_data_n.csv')\n",
    "df['target'] = (df['target'] > df['target'].median()).astype(int)\n",
    "features_train = df.drop('target', axis=1)\n",
    "target_train = df['target']\n",
    "\n",
    "df_val = pd.read_csv('/datasets/test_data_n.csv')\n",
    "df_val['target'] = (df_val['target'] > df['target'].median()).astype(int)\n",
    "features_valid = df_val.drop('target', axis=1)\n",
    "target_valid = df_val['target']\n",
    "\n",
    "# < write code here >\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(units=1, input_dim=features_train.shape[1], activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='sgd')\n",
    "model.fit(features_train, target_train, validation_data=(features_valid, target_valid), verbose=2, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model's accuracy using validation data\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "df = pd.read_csv('/datasets/train_data_n.csv')\n",
    "df['target'] = (df['target'] > df['target'].median()).astype(int)\n",
    "features_train = df.drop('target', axis=1)\n",
    "target_train = df['target']\n",
    "\n",
    "df_val = pd.read_csv('/datasets/test_data_n.csv')\n",
    "df_val['target'] = (df_val['target'] > df['target'].median()).astype(int)\n",
    "features_valid = df_val.drop('target', axis=1)\n",
    "target_valid = df_val['target']\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(units=1, input_dim=features_train.shape[1], \n",
    "                             activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='sgd')\n",
    "model.fit(features_train, target_train, epochs=5, verbose=0,\n",
    "          validation_data=(features_valid, target_valid))\n",
    "\n",
    "\n",
    "# < write code here >\n",
    "predictions = model.predict(features_valid) > 0.5\n",
    "#print(predictions)\n",
    "score = accuracy_score(predictions, target_valid)\n",
    "print(\"Accuracy:\", score)# < write code here >)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trace quality at each epoch\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "df = pd.read_csv('/datasets/train_data_n.csv')\n",
    "df['target'] = (df['target'] > df['target'].median()).astype(int)\n",
    "features_train = df.drop('target', axis=1)\n",
    "target_train = df['target']\n",
    "\n",
    "df_val = pd.read_csv('/datasets/test_data_n.csv')\n",
    "df_val['target'] = (df_val['target'] > df['target'].median()).astype(int)\n",
    "features_valid = df_val.drop('target', axis=1)\n",
    "target_valid = df_val['target']\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(units=1, input_dim=features_train.shape[1], \n",
    "                             activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['acc'])\n",
    "model.fit(features_train, target_train, epochs=10, verbose=2,\n",
    "          validation_data=(features_valid, target_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Connected Neural Networks in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "df = pd.read_csv('/datasets/train_data_n.csv')\n",
    "df['target'] = (df['target'] > df['target'].median()).astype(int)\n",
    "features_train = df.drop('target', axis=1)\n",
    "target_train = df['target']\n",
    "\n",
    "df_val = pd.read_csv('/datasets/test_data_n.csv')\n",
    "df_val['target'] = (df_val['target'] > df['target'].median()).astype(int)\n",
    "features_valid = df_val.drop('target', axis=1)\n",
    "target_valid = df_val['target']\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "# < write code here >\n",
    "#adding hidden layers with different neurons\n",
    "model.add(keras.layers.Dense(units=10, activation='sigmoid',input_dim=features_train.shape[1]))\n",
    "model.add(keras.layers.Dense(units=1, activation='sigmoid', input_dim=features_train.shape[1]))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['acc'])\n",
    "\n",
    "model.fit(features_train, target_train, epochs=10, verbose=2,\n",
    "          validation_data=(features_valid, target_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with Images in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/datasets/ds_cv_images/face.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-694a3a7b3405>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/datasets/ds_cv_images/face.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode)\u001b[0m\n\u001b[0;32m   2807\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2808\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2809\u001b[1;33m         \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2810\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2811\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/datasets/ds_cv_images/face.png'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "image = Image.open('/datasets/ds_cv_images/face.png')\n",
    "array = np.array(image)\n",
    "print(array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we get a 2-D array\n",
    "[[255 255 255 255 237 217 239 255 255 255 255 255 255]\n",
    " [255 255 190  75  29  29  30  81 198 255 255 255 255]\n",
    " [255 147  30  29  29  29  29  29  31 160 255 255 255]\n",
    " [185  29  29  29  29  29  29  29  29  31 198 255 255]\n",
    " [ 61  29  29  29  29  29  29  29  29  29  74 255 255]\n",
    " [108 121 121 121 121 121 121 121 121 121 102 219 255]\n",
    " [250 255 255 255 255 255 255 255 255 255 238 107 168]\n",
    " [255 238 153 150 152 244 201 152 150 178 253 103 144]\n",
    " [248 243 121 108 114 225 184 130 112 154 235 103  62]\n",
    " [197 255 227 168 231 149 230 196 179 251 183  29  29]\n",
    " [105 255 255 219 195 191 184 195 235 255  91  29  29]\n",
    " [ 30 187 255 234 218 218 218 218 243 174  29  29  29]\n",
    " [ 29  38 180 255 255 255 255 255 169  35  29  29  29]\n",
    " [ 29  29  29  82 153 174 150  76  29  29  29  29  29]\n",
    " [ 29  29  29  29  29  29  29  29  29  29  29  29  29]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image = Image.open('/datasets/ds_cv_images/face.png')\n",
    "array = np.array(image)\n",
    "\n",
    "# < write code here >\n",
    "plt.imshow(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set color to balck and white\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image = Image.open('/datasets/ds_cv_images/face.png')\n",
    "array = np.array(image)\n",
    "\n",
    "plt.imshow(array, cmap='gray')# < write code here >)\n",
    "# < write code here >\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#repaint corners\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image = Image.open('/datasets/ds_cv_images/face.png')\n",
    "array = np.array(image)\n",
    "\n",
    "# < write code here >\n",
    "#print(array.shape)\n",
    "array[0][0] = 0\n",
    "array[14][12] = 255\n",
    "#print(array)\n",
    "\n",
    "plt.imshow(array, cmap='gray')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize the scale\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image = Image.open('/datasets/ds_cv_images/face.png')\n",
    "array = np.array(image)\n",
    "\n",
    "# < write code here >\n",
    "array = array / 255\n",
    "#print(array)\n",
    "\n",
    "plt.imshow(array, cmap='gray')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Color images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0, 255],\n",
       "       [255,   0]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[0, 255],\n",
    "                    [255, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  0, 255,   0],\n",
       "        [128,   0, 255]],\n",
       "\n",
       "       [[ 12,  89,   0],\n",
       "        [  5,  89, 245]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[[0, 255, 0], [128, 0, 255]], \n",
    "                    [[12, 89, 0], [5,  89, 245]]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image = Image.open('/datasets/ds_cv_images/cat.jpg')\n",
    "array = np.array(image)\n",
    "\n",
    "# < write code here >\n",
    "print(array.shape)\n",
    "#print(array)\n",
    "#print(array.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output the red channel only\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image = Image.open('/datasets/ds_cv_images/cat.jpg')\n",
    "array = np.array(image)\n",
    "\n",
    "red_channel =array[:,:,0] \n",
    "# < write code here >\n",
    "\n",
    "plt.imshow(red_channel)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Classification\n",
    "\n",
    "-  We need to build a ten-class classifier for the clothing store aggregator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "features_train = np.load('/datasets/fashion_mnist/train_features.npy')\n",
    "target_train = np.load('/datasets/fashion_mnist/train_target.npy')\n",
    "features_test = np.load('/datasets/fashion_mnist/test_features.npy')\n",
    "target_test = np.load('/datasets/fashion_mnist/test_target.npy')\n",
    "\n",
    "print(\"Train:\", features_train.shape)# < write code here >)\n",
    "print(\"Test:\", features_test.shape)# < write code here >)\n",
    "\n",
    "print(\"First image class:\", target_train[0])# < write code here >)\n",
    "plt.imshow(features_train[0], cmap='gray')# < write code here >)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lis = [[0, 255, 0], [128, 0, 255]]\n",
    "a_lis = np.array(lis)\n",
    "type(a_lis)\n",
    "a_lis.shape\n",
    "len(a_lis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[[0, 255, 0], [128, 0, 255]], \n",
    "                    [[12, 89, 0], [5,  89, 245]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.reshape(x, (3,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D to 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "features_train = np.load('/datasets/fashion_mnist/train_features.npy')\n",
    "target_train = np.load('/datasets/fashion_mnist/train_target.npy')\n",
    "features_test = np.load('/datasets/fashion_mnist/test_features.npy')\n",
    "target_test = np.load('/datasets/fashion_mnist/test_target.npy')\n",
    "\n",
    "# < write code here >\n",
    "features_train = features_train.reshape(features_train.shape[0], 28 * 28)\n",
    "features_test = features_test.reshape(features_test.shape[0], 28 * 28)\n",
    "\n",
    "print(\"Train:\", features_train.shape)\n",
    "print(\"Test:\", features_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and train a neural network. First, create a logistic regression with ten classes in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "features_train = np.load('/datasets/fashion_mnist/train_features.npy')\n",
    "target_train = np.load('/datasets/fashion_mnist/train_target.npy')\n",
    "features_test = np.load('/datasets/fashion_mnist/test_features.npy')\n",
    "target_test = np.load('/datasets/fashion_mnist/test_target.npy')\n",
    "\n",
    "features_train = features_train.reshape(features_train.shape[0], 28 * 28)\n",
    "features_test = features_test.reshape(features_test.shape[0], 28 * 28)\n",
    "\n",
    "model = keras.models.Sequential()# < write code here >\n",
    "model.add(keras.layers.Dense(units=10, activation='softmax', input_dim=28*28))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['acc'])\n",
    "model.fit(features_train, target_train, epochs=1, verbose=2,\n",
    "          validation_data=(features_test, target_test))\n",
    "\n",
    "# < write code here >\n",
    "\n",
    "#model.fit(# < write code here >)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-layer Network Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how to train a model on the server\n",
    "#pretest the code\n",
    "#1. loading the training sample\n",
    "def load_train(path):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train(path):\n",
    "    features_train = np.load(path + 'train_features.npy')\n",
    "    target_train = np.load(path + 'train_target.npy')\n",
    "    features_train = features_train.reshape(features_train.shape[0], 28 * 28) / 255.\n",
    "    return features_train, target_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a model for a neural network and use the return command to return it\n",
    "#Use the input_shape parameter to specify the data size in the first layer.\n",
    "def create_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, input_shape=input_shape, activation='softmax'))\n",
    "    model.compile(optimizer='sgd', loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['acc'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#launch the model\n",
    "def train_model(model, train_data, test_data, batch_size, epochs,\n",
    "                steps_per_epoch, validation_steps):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_data, test_data, batch_size=32, epochs=5,\n",
    "                steps_per_epoch=None, validation_steps=None):\n",
    "\n",
    "    features_train, target_train = train_data\n",
    "    features_test, target_test = test_data\n",
    "    model.fit(features_train, target_train, \n",
    "              validation_data=(features_test, target_test),\n",
    "              batch_size=batch_size, epochs=epochs,\n",
    "              steps_per_epoch=steps_per_epoch,\n",
    "              validation_steps=validation_steps,\n",
    "              verbose=2, shuffle=True)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take a look at the entire code for logistic regression:\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "import numpy as np\n",
    "\n",
    "def load_train(path):\n",
    "    features_train = np.load(path + 'train_features.npy')\n",
    "    target_train = np.load(path + 'train_target.npy')\n",
    "    features_train = features_train.reshape(features_train.shape[0], 28 * 28) / 255.\n",
    "    return features_train, target_train\n",
    "\n",
    "def create_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, input_shape=input_shape, activation='softmax'))\n",
    "    model.compile(optimizer='sgd', loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['acc'])\n",
    "\n",
    "    return model\n",
    "\n",
    "def train_model(model, train_data, test_data, batch_size=32, epochs=5,\n",
    "               steps_per_epoch=None, validation_steps=None):\n",
    "\n",
    "    features_train, target_train = train_data\n",
    "    features_test, target_test = test_data\n",
    "    model.fit(features_train, target_train, \n",
    "              validation_data=(features_test, target_test),\n",
    "              batch_size=batch_size, epochs=epochs,\n",
    "              steps_per_epoch=steps_per_epoch,\n",
    "              validation_steps=validation_steps,\n",
    "              verbose=2, shuffle=True)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-dimensional convolution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's express a one-dimensional convolution in Python\n",
    "def convolve(sequence, weights):\n",
    "    convolution = np.zeros(len(sequence) - len(weights) + 1)\n",
    "    for i in range(convolution.shape[0]):\n",
    "        convolution[i] = np.sum(np.array(weights) * np.array(sequence[i:i + len(weights)]))\n",
    "    return convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = [2, 3, 5, 7, 11]\n",
    "w = [-1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2., 2., 4.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convolve(s, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convolution = np.zeros(len(s) - len(w) + 1)\n",
    "convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convolution.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 5])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(s[1:1 + len(w)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two-dimensional Convolution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = [[1, 1, 1, 0, 0],\n",
    "     [0, 1, 1, 1, 0],\n",
    "     [0, 0, 1, 1, 1],\n",
    "     [0, 0, 1, 1, 0],\n",
    "     [0, 1, 1, 0, 0]]\n",
    "\n",
    "w = [[1, 0, 1],\n",
    "     [0, 1, 0],\n",
    "     [1, 0, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = [[0, -3], [7, 13]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional layers in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.layers.Conv2D(filters, kernel_size, strides, padding, activation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here's what all the parameters mean:\n",
    "    - **filters**: The number of filters, which corresponds to the size of the output tensor.\n",
    "    - **kernel_size**: The spatial size of the filter K. Any filter is a tensor with the size K×K×D, where D is equal to the depth of the input image.\n",
    "    - **strides**: A stride determines how far the filter shifts over the input matrix. It's set to 1 by default.\n",
    "    - **padding**: This parameter determines the width of the zero padding. There are two types of padding: valid and same. The default type of padding is valid and is equal to zero. Same sets the size of the padding automatically so that the width and height of the output tensor is equal to the width and height of the input tensor.\n",
    "    - **activation**: This function is applied immediately after the convolution. You can use the activation functions already familiar to you: 'relu' and 'sigmoid'. By default, this parameter is None, i.e. activation is disabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# this tensor has a size of (None, 32, 32, 3)\n",
    "# the first dimension defines different objects\n",
    "# it's set to None because the size of the batch is unknown\n",
    "\n",
    "model.add(Conv2D(filters=4, kernel_size=(3, 3), input_shape=(32, 32, 3)))\n",
    "\n",
    "# this tensor has a size of (None, 30, 30, 4)\n",
    "\n",
    "model.add(Flatten()) #makes the multidimensional into a one dimensional\n",
    "\n",
    "# this tensor has a size of (None, 3600)\n",
    "# where 3600 = 30 * 30 * 4\n",
    "\n",
    "model.add(Dense(...))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "features_train = np.load('/datasets/fashion_mnist/train_features.npy')\n",
    "target_train = np.load('/datasets/fashion_mnist/train_target.npy')\n",
    "features_test = np.load('/datasets/fashion_mnist/test_features.npy')\n",
    "target_test = np.load('/datasets/fashion_mnist/test_target.npy')\n",
    "\n",
    "# Change the image's dimensions and set it to a range of [0, 1].\n",
    "# While changing the size, you can set one of the dimensions to -1, \n",
    "# so that it is calculated automatically\n",
    "features_train = features_train.reshape(-1, 28, 28, 1) / 255.0\n",
    "features_test = features_test.reshape(-1, 28, 28, 1) / 255.0\n",
    "\n",
    "model = Sequential()\n",
    "# < write code here >\n",
    "model.add(Conv2D(filters=4, kernel_size=(3, 3), input_shape=(28, 28, 1)))\n",
    "model.add(Flatten())          \n",
    "model.add(Dense(10, activation='softmax'))         \n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['acc'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- conv2D: (None, 26, 26, 4), 40parameters\n",
    "- flatten (None, 2704), 0params\n",
    "- dense (None, 10), 27050params\n",
    "    - total params; 27,090"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "features_train = np.load('/datasets/fashion_mnist/train_features.npy')\n",
    "target_train = np.load('/datasets/fashion_mnist/train_target.npy')\n",
    "features_test = np.load('/datasets/fashion_mnist/test_features.npy')\n",
    "target_test = np.load('/datasets/fashion_mnist/test_target.npy')\n",
    "features_train = features_train.reshape(-1, 28, 28, 1) / 255.0\n",
    "features_test = features_test.reshape(-1, 28, 28, 1) / 255.0\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=4, kernel_size=(3, 3), padding='same',activation=\"relu\", input_shape=(28, 28, 1)))\n",
    "model.add(Conv2D(filters=4, kernel_size=(3, 3), strides=2, padding='same',activation=\"relu\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['acc'])\n",
    "model.summary()\n",
    "model.fit(features_train, target_train, epochs=1, verbose=1,\n",
    "steps_per_epoch=1, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
