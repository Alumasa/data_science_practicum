{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some data\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('/datasets/train_data_n.csv')\n",
    "features = data.drop('target', axis=1)\n",
    "target = data['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in sklearn\n",
    "# import from sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# create the model\n",
    "model = LinearRegression()\n",
    "\n",
    "# train the model\n",
    "model.fit(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in keras\n",
    "# import Keras\n",
    "from tensorflow import keras\n",
    "\n",
    "# create the model\n",
    "model = keras.models.Sequential()\n",
    "# indicate how the neural network is arranged\n",
    "model.add(keras.layers.Dense(units=1, input_dim=features.shape[1]))\n",
    "# indicate how the neural network is trained\n",
    "model.compile(loss='mean_squared_error', optimizer='sgd')\n",
    "\n",
    "# train the model\n",
    "model.fit(features, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's set the model class to Sequential. \n",
    "- This class is used for models with sequential layers. Layer is a set of neurons that share the same input and output.\n",
    "\n",
    "- The keras.layers.Dense() command creates one layer of neurons. \n",
    "- \"Dense\" means that every input will be connected to every neuron, or output. \n",
    "- The units parameter sets the number of neurons in the layer, and input_dim sets the number of inputs in the layer. \n",
    "- Note that this parameter doesn't take the bias into account.\n",
    "- To add the fully connected layer to the model, call the model.add() method:\n",
    "- `model.compile` - It prepares the model for training. \n",
    "- Specify MSE as the regression task loss function for the loss parameter. \n",
    "-Set the gradient descent method for the optimizer='sgd' parameter. Remember, we'll be training neural networks using SGD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Layers where all inputs are connected to all neurons are called **fully connected layers**.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`keras.layers.Dense(units=2, input_dim=3)` - two neurons and three inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "\n",
    "data = pd.read_csv('/datasets/train_data_n.csv')\n",
    "features = data.drop('target', axis=1)\n",
    "target = data['target']\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(units=1, input_dim=features.shape[1]))\n",
    "model.compile(loss='mean_squared_error', optimizer='sgd')\n",
    "model.fit(features, target, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#epochs = how many times has our data passed through the algorithm) to get the MSE to be less than 6.55.\n",
    "model.fit(features, target, verbose=2, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the loss function value for the validation set.\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "\n",
    "data_train = pd.read_csv('/datasets/train_data_n.csv')\n",
    "features_train = data_train.drop('target', axis=1)\n",
    "target_train = data_train['target']\n",
    "\n",
    "data_valid = pd.read_csv('/datasets/test_data_n.csv')\n",
    "features_valid = data_valid.drop('target', axis=1)\n",
    "target_valid = data_valid['target']\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(units=1, input_dim=features_train.shape[1]))\n",
    "model.compile(loss='mean_squared_error', optimizer='sgd')\n",
    "model.fit(features_train, target_train, validation_data=(features_valid, target_valid), epochs=5, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply the activation function to the fully connected layer:\n",
    "keras.layers.Dense(units=1, input_dim=features_train.shape[1], activation='sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change the loss function from MSE to binary_crossentropy;\n",
    "model.compile(loss='binary_crossentropy', optimizer='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "\n",
    "df = pd.read_csv('/datasets/train_data_n.csv')\n",
    "df['target'] = (df['target'] > df['target'].median()).astype(int)\n",
    "features_train = df.drop('target', axis=1)\n",
    "target_train = df['target']\n",
    "\n",
    "df_val = pd.read_csv('/datasets/test_data_n.csv')\n",
    "df_val['target'] = (df_val['target'] > df['target'].median()).astype(int)\n",
    "features_valid = df_val.drop('target', axis=1)\n",
    "target_valid = df_val['target']\n",
    "\n",
    "# < write code here >\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(units=1, input_dim=features_train.shape[1], activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='sgd')\n",
    "model.fit(features_train, target_train, validation_data=(features_valid, target_valid), verbose=2, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model's accuracy using validation data\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "df = pd.read_csv('/datasets/train_data_n.csv')\n",
    "df['target'] = (df['target'] > df['target'].median()).astype(int)\n",
    "features_train = df.drop('target', axis=1)\n",
    "target_train = df['target']\n",
    "\n",
    "df_val = pd.read_csv('/datasets/test_data_n.csv')\n",
    "df_val['target'] = (df_val['target'] > df['target'].median()).astype(int)\n",
    "features_valid = df_val.drop('target', axis=1)\n",
    "target_valid = df_val['target']\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(units=1, input_dim=features_train.shape[1], \n",
    "                             activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='sgd')\n",
    "model.fit(features_train, target_train, epochs=5, verbose=0,\n",
    "          validation_data=(features_valid, target_valid))\n",
    "\n",
    "\n",
    "# < write code here >\n",
    "predictions = model.predict(features_valid) > 0.5\n",
    "#print(predictions)\n",
    "score = accuracy_score(predictions, target_valid)\n",
    "print(\"Accuracy:\", score)# < write code here >)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trace quality at each epoch\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "df = pd.read_csv('/datasets/train_data_n.csv')\n",
    "df['target'] = (df['target'] > df['target'].median()).astype(int)\n",
    "features_train = df.drop('target', axis=1)\n",
    "target_train = df['target']\n",
    "\n",
    "df_val = pd.read_csv('/datasets/test_data_n.csv')\n",
    "df_val['target'] = (df_val['target'] > df['target'].median()).astype(int)\n",
    "features_valid = df_val.drop('target', axis=1)\n",
    "target_valid = df_val['target']\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(units=1, input_dim=features_train.shape[1], \n",
    "                             activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['acc'])\n",
    "model.fit(features_train, target_train, epochs=10, verbose=2,\n",
    "          validation_data=(features_valid, target_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Connected Neural Networks in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "df = pd.read_csv('/datasets/train_data_n.csv')\n",
    "df['target'] = (df['target'] > df['target'].median()).astype(int)\n",
    "features_train = df.drop('target', axis=1)\n",
    "target_train = df['target']\n",
    "\n",
    "df_val = pd.read_csv('/datasets/test_data_n.csv')\n",
    "df_val['target'] = (df_val['target'] > df['target'].median()).astype(int)\n",
    "features_valid = df_val.drop('target', axis=1)\n",
    "target_valid = df_val['target']\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "# < write code here >\n",
    "#adding hidden layers with different neurons\n",
    "model.add(keras.layers.Dense(units=10, activation='sigmoid',input_dim=features_train.shape[1]))\n",
    "model.add(keras.layers.Dense(units=1, activation='sigmoid', input_dim=features_train.shape[1]))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['acc'])\n",
    "\n",
    "model.fit(features_train, target_train, epochs=10, verbose=2,\n",
    "          validation_data=(features_valid, target_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with Images in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/datasets/ds_cv_images/face.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-694a3a7b3405>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/datasets/ds_cv_images/face.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode)\u001b[0m\n\u001b[0;32m   2807\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2808\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2809\u001b[1;33m         \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2810\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2811\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/datasets/ds_cv_images/face.png'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "image = Image.open('/datasets/ds_cv_images/face.png')\n",
    "array = np.array(image)\n",
    "print(array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we get a 2-D array\n",
    "[[255 255 255 255 237 217 239 255 255 255 255 255 255]\n",
    " [255 255 190  75  29  29  30  81 198 255 255 255 255]\n",
    " [255 147  30  29  29  29  29  29  31 160 255 255 255]\n",
    " [185  29  29  29  29  29  29  29  29  31 198 255 255]\n",
    " [ 61  29  29  29  29  29  29  29  29  29  74 255 255]\n",
    " [108 121 121 121 121 121 121 121 121 121 102 219 255]\n",
    " [250 255 255 255 255 255 255 255 255 255 238 107 168]\n",
    " [255 238 153 150 152 244 201 152 150 178 253 103 144]\n",
    " [248 243 121 108 114 225 184 130 112 154 235 103  62]\n",
    " [197 255 227 168 231 149 230 196 179 251 183  29  29]\n",
    " [105 255 255 219 195 191 184 195 235 255  91  29  29]\n",
    " [ 30 187 255 234 218 218 218 218 243 174  29  29  29]\n",
    " [ 29  38 180 255 255 255 255 255 169  35  29  29  29]\n",
    " [ 29  29  29  82 153 174 150  76  29  29  29  29  29]\n",
    " [ 29  29  29  29  29  29  29  29  29  29  29  29  29]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image = Image.open('/datasets/ds_cv_images/face.png')\n",
    "array = np.array(image)\n",
    "\n",
    "# < write code here >\n",
    "plt.imshow(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set color to balck and white\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image = Image.open('/datasets/ds_cv_images/face.png')\n",
    "array = np.array(image)\n",
    "\n",
    "plt.imshow(array, cmap='gray')# < write code here >)\n",
    "# < write code here >\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#repaint corners\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image = Image.open('/datasets/ds_cv_images/face.png')\n",
    "array = np.array(image)\n",
    "\n",
    "# < write code here >\n",
    "#print(array.shape)\n",
    "array[0][0] = 0\n",
    "array[14][12] = 255\n",
    "#print(array)\n",
    "\n",
    "plt.imshow(array, cmap='gray')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize the scale\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image = Image.open('/datasets/ds_cv_images/face.png')\n",
    "array = np.array(image)\n",
    "\n",
    "# < write code here >\n",
    "array = array / 255\n",
    "#print(array)\n",
    "\n",
    "plt.imshow(array, cmap='gray')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Color images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0, 255],\n",
       "       [255,   0]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[0, 255],\n",
    "                    [255, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  0, 255,   0],\n",
       "        [128,   0, 255]],\n",
       "\n",
       "       [[ 12,  89,   0],\n",
       "        [  5,  89, 245]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[[0, 255, 0], [128, 0, 255]], \n",
    "                    [[12, 89, 0], [5,  89, 245]]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image = Image.open('/datasets/ds_cv_images/cat.jpg')\n",
    "array = np.array(image)\n",
    "\n",
    "# < write code here >\n",
    "print(array.shape)\n",
    "#print(array)\n",
    "#print(array.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output the red channel only\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image = Image.open('/datasets/ds_cv_images/cat.jpg')\n",
    "array = np.array(image)\n",
    "\n",
    "red_channel =array[:,:,0] \n",
    "# < write code here >\n",
    "\n",
    "plt.imshow(red_channel)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Classification\n",
    "\n",
    "-  We need to build a ten-class classifier for the clothing store aggregator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "features_train = np.load('/datasets/fashion_mnist/train_features.npy')\n",
    "target_train = np.load('/datasets/fashion_mnist/train_target.npy')\n",
    "features_test = np.load('/datasets/fashion_mnist/test_features.npy')\n",
    "target_test = np.load('/datasets/fashion_mnist/test_target.npy')\n",
    "\n",
    "print(\"Train:\", features_train.shape)# < write code here >)\n",
    "print(\"Test:\", features_test.shape)# < write code here >)\n",
    "\n",
    "print(\"First image class:\", target_train[0])# < write code here >)\n",
    "plt.imshow(features_train[0], cmap='gray')# < write code here >)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[[0, 255, 0], [128, 0, 255]], \n",
    "                    [[12, 89, 0], [5,  89, 245]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.reshape(x, (3,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D to 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "features_train = np.load('/datasets/fashion_mnist/train_features.npy')\n",
    "target_train = np.load('/datasets/fashion_mnist/train_target.npy')\n",
    "features_test = np.load('/datasets/fashion_mnist/test_features.npy')\n",
    "target_test = np.load('/datasets/fashion_mnist/test_target.npy')\n",
    "\n",
    "# < write code here >\n",
    "features_train = features_train.reshape(features_train.shape[0], 28 * 28)\n",
    "features_test = features_test.reshape(features_test.shape[0], 28 * 28)\n",
    "\n",
    "print(\"Train:\", features_train.shape)\n",
    "print(\"Test:\", features_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and train a neural network. First, create a logistic regression with ten classes in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "features_train = np.load('/datasets/fashion_mnist/train_features.npy')\n",
    "target_train = np.load('/datasets/fashion_mnist/train_target.npy')\n",
    "features_test = np.load('/datasets/fashion_mnist/test_features.npy')\n",
    "target_test = np.load('/datasets/fashion_mnist/test_target.npy')\n",
    "\n",
    "features_train = features_train.reshape(features_train.shape[0], 28 * 28)\n",
    "features_test = features_test.reshape(features_test.shape[0], 28 * 28)\n",
    "\n",
    "model = keras.models.Sequential()# < write code here >\n",
    "model.add(keras.layers.Dense(units=10, activation='softmax', input_dim=28*28))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['acc'])\n",
    "model.fit(features_train, target_train, epochs=1, verbose=2,\n",
    "          validation_data=(features_test, target_test))\n",
    "\n",
    "# < write code here >\n",
    "\n",
    "#model.fit(# < write code here >)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
