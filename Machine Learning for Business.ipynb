{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean before: 396.9714285714286\n",
      "Mean after: 470.5285714285714\n",
      "p-value:  6.181958220818264e-29\n",
      "Reject null hypothesis: average purchase amount is likely to increase\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats as st\n",
    "\n",
    "sample_before = pd.Series([\n",
    "    436, 397, 433, 412, 367, 353, 440, 375, 414, \n",
    "    410, 434, 356, 377, 403, 434, 377, 437, 383,\n",
    "    388, 412, 350, 392, 354, 362, 392, 441, 371, \n",
    "    350, 364, 449, 413, 401, 382, 445, 366, 435,\n",
    "    442, 413, 386, 390, 350, 364, 418, 369, 369, \n",
    "    368, 429, 388, 397, 393, 373, 438, 385, 365,\n",
    "    447, 408, 379, 411, 358, 368, 442, 366, 431,\n",
    "    400, 449, 422, 423, 427, 361, 354])\n",
    "\n",
    "sample_after = pd.Series([\n",
    "    439, 518, 452, 505, 493, 470, 498, 442, 497, \n",
    "    423, 524, 442, 459, 452, 463, 488, 497, 500,\n",
    "    476, 501, 456, 425, 438, 435, 516, 453, 505, \n",
    "    441, 477, 469, 497, 502, 442, 449, 465, 429,\n",
    "    442, 472, 466, 431, 490, 475, 447, 435, 482, \n",
    "    434, 525, 510, 494, 493, 495, 499, 455, 464,\n",
    "    509, 432, 476, 438, 512, 423, 428, 499, 492, \n",
    "    493, 467, 493, 468, 420, 513, 427])\n",
    "\n",
    "print(\"Mean before:\", sample_before.mean())# < write code here >)\n",
    "print(\"Mean after:\", sample_after.mean())# < write code here >)\n",
    "\n",
    "\n",
    "# critical level of significance\n",
    "# if p-value is less than that, hypothesis is rejected\n",
    "alpha = 0.05# < write code here >)\n",
    "\n",
    "# one-tailed test: p-value will be half as large\n",
    "results = st.ttest_ind(sample_before, sample_after, equal_var=True)\n",
    "pvalue = results.pvalue# < write code here >)\n",
    "\n",
    "print('p-value: ', pvalue)\n",
    "\n",
    "if pvalue < alpha:\n",
    "    print(\"Reject null hypothesis: average purchase amount is likely to increase\")\n",
    "else:\n",
    "    print(\"Failed to reject null hypothesis: average purchase amount is unlikely to increase\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confidence Interval\n",
    "\n",
    "The confidence interval of the average purchase amount is a range built around the sample mean and containing the true mean for the average purchase amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 470.5285714285714\n",
      "95% confidence interval: (463.357753651609, 477.6993892055338)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats as st\n",
    "\n",
    "sample = pd.Series([\n",
    "    439, 518, 452, 505, 493, 470, 498, 442, 497, \n",
    "    423, 524, 442, 459, 452, 463, 488, 497, 500,\n",
    "    476, 501, 456, 425, 438, 435, 516, 453, 505, \n",
    "    441, 477, 469, 497, 502, 442, 449, 465, 429,\n",
    "    442, 472, 466, 431, 490, 475, 447, 435, 482, \n",
    "    434, 525, 510, 494, 493, 495, 499, 455, 464,\n",
    "    509, 432, 476, 438, 512, 423, 428, 499, 492, \n",
    "    493, 467, 493, 468, 420, 513, 427])\n",
    "\n",
    "print(\"Mean:\", sample.mean())\n",
    "\n",
    "confidence_interval = st.t.interval(\n",
    "    0.95, len(sample)-1, sample.mean(), sample.sem())# < wrtite code here >)\n",
    "\n",
    "print(\"95% confidence interval:\", confidence_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.t.interval?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrapping for Confidence Interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.Series([\n",
    "    10.7,  9.58,  7.74,  8.3 , 11.82,  9.74, 10.18,  8.43,  8.71,\n",
    "     6.84,  9.26, 11.61, 11.08,  8.94,  8.44, 10.41,  9.36, 10.85,\n",
    "    10.41,  8.37,  8.99, 10.17,  7.78, 10.79, 10.61, 10.87,  7.43,\n",
    "     8.44,  9.44,  8.26,  7.98, 11.27, 11.61,  9.84, 12.47,  7.8,\n",
    "    10.54,  8.99,  7.33,  8.55,  8.06, 10.62, 10.41,  9.29,  9.98,\n",
    "     9.46,  9.99,  8.62, 11.34, 11.21, 15.19, 20.85, 19.15, 19.01,\n",
    "    15.24, 16.66, 17.62, 18.22, 17.2, 15.76, 16.89, 15.22, 18.7,\n",
    "    14.84, 14.88, 19.41, 18.54, 17.85, 18.31, 13.68, 18.46, 13.99,\n",
    "    16.38, 16.88, 17.82, 15.17, 15.16, 18.15, 15.08, 15.91, 16.82,\n",
    "    16.85, 18.04, 17.51, 18.44, 15.33, 16.07, 17.22, 15.9, 18.03,\n",
    "    17.26, 17.6, 16.77, 17.45, 13.73, 14.95, 15.57, 19.19, 14.39,\n",
    "    15.76])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69    13.68\n",
      "dtype: float64\n",
      "69    13.68\n",
      "dtype: float64\n",
      "69    13.68\n",
      "dtype: float64\n",
      "69    13.68\n",
      "dtype: float64\n",
      "69    13.68\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#subsamples for bootstrapping\n",
    "for i in range(5):\n",
    "    # extract one random element from sample 1\n",
    "    # specify random_state for reproducibility\n",
    "    print(data.sample(1, random_state=12345))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import RandomState\n",
    "state = RandomState(12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69    13.68\n",
      "dtype: float64\n",
      "27    8.44\n",
      "dtype: float64\n",
      "36    10.54\n",
      "dtype: float64\n",
      "84    18.44\n",
      "dtype: float64\n",
      "59    15.76\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    # extract one random element from sample 1\n",
    "    print(data.sample(1, random_state=state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without replacement\n",
      "2    3\n",
      "0    1\n",
      "3    4\n",
      "1    2\n",
      "4    5\n",
      "dtype: int64\n",
      "With replacement\n",
      "0    1\n",
      "1    2\n",
      "1    2\n",
      "3    4\n",
      "1    2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#the same element can fall into a subsample several times\n",
    "example_data = pd.Series([1, 2, 3, 4, 5])\n",
    "print(\"Without replacement\")\n",
    "print(example_data.sample(frac=1, replace=False, random_state=state))\n",
    "print(\"With replacement\")\n",
    "print(example_data.sample(frac=1, replace=True, random_state=state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.1922\n",
      "20.85\n",
      "19.20660000000001\n",
      "19.028400000000012\n",
      "19.42440000000001\n",
      "19.42440000000001\n",
      "20.85\n",
      "19.42440000000001\n",
      "19.42440000000001\n",
      "19.19\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.Series([\n",
    "    10.7 ,  9.58,  7.74,  8.3 , 11.82,  9.74, 10.18,  8.43,  8.71,\n",
    "     6.84,  9.26, 11.61, 11.08,  8.94,  8.44, 10.41,  9.36, 10.85,\n",
    "    10.41,  8.37,  8.99, 10.17,  7.78, 10.79, 10.61, 10.87,  7.43,\n",
    "     8.44,  9.44,  8.26,  7.98, 11.27, 11.61,  9.84, 12.47,  7.8 ,\n",
    "    10.54,  8.99,  7.33,  8.55,  8.06, 10.62, 10.41,  9.29,  9.98,\n",
    "     9.46,  9.99,  8.62, 11.34, 11.21, 15.19, 20.85, 19.15, 19.01,\n",
    "    15.24, 16.66, 17.62, 18.22, 17.2 , 15.76, 16.89, 15.22, 18.7 ,\n",
    "    14.84, 14.88, 19.41, 18.54, 17.85, 18.31, 13.68, 18.46, 13.99,\n",
    "    16.38, 16.88, 17.82, 15.17, 15.16, 18.15, 15.08, 15.91, 16.82,\n",
    "    16.85, 18.04, 17.51, 18.44, 15.33, 16.07, 17.22, 15.9 , 18.03,\n",
    "    17.26, 17.6 , 16.77, 17.45, 13.73, 14.95, 15.57, 19.19, 14.39,\n",
    "    15.76])\n",
    "\n",
    "state = np.random.RandomState(12345)\n",
    "\n",
    "for i in range(10):\n",
    "    subsample = data.sample(frac=1, replace=True, random_state=state)# < write code here >\n",
    "    print(subsample.quantile(0.99))# < write code here >)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      19.1922\n",
      "1      20.8500\n",
      "2      19.2066\n",
      "3      19.0284\n",
      "4      19.4244\n",
      "        ...   \n",
      "995    19.4244\n",
      "996    19.4100\n",
      "997    20.8500\n",
      "998    20.8500\n",
      "999    18.7031\n",
      "Length: 1000, dtype: float64\n",
      "19.011400000000002\n",
      "20.85\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.Series([\n",
    "    10.7 ,  9.58,  7.74,  8.3 , 11.82,  9.74, 10.18,  8.43,  8.71,\n",
    "     6.84,  9.26, 11.61, 11.08,  8.94,  8.44, 10.41,  9.36, 10.85,\n",
    "    10.41,  8.37,  8.99, 10.17,  7.78, 10.79, 10.61, 10.87,  7.43,\n",
    "     8.44,  9.44,  8.26,  7.98, 11.27, 11.61,  9.84, 12.47,  7.8 ,\n",
    "    10.54,  8.99,  7.33,  8.55,  8.06, 10.62, 10.41,  9.29,  9.98,\n",
    "     9.46,  9.99,  8.62, 11.34, 11.21, 15.19, 20.85, 19.15, 19.01,\n",
    "    15.24, 16.66, 17.62, 18.22, 17.2 , 15.76, 16.89, 15.22, 18.7 ,\n",
    "    14.84, 14.88, 19.41, 18.54, 17.85, 18.31, 13.68, 18.46, 13.99,\n",
    "    16.38, 16.88, 17.82, 15.17, 15.16, 18.15, 15.08, 15.91, 16.82,\n",
    "    16.85, 18.04, 17.51, 18.44, 15.33, 16.07, 17.22, 15.9 , 18.03,\n",
    "    17.26, 17.6 , 16.77, 17.45, 13.73, 14.95, 15.57, 19.19, 14.39,\n",
    "    15.76])\n",
    "\n",
    "state = np.random.RandomState(12345)\n",
    "\n",
    "# Store the 99% quantile values to the values variable\n",
    "values = []\n",
    "for i in range(1000):\n",
    "    subsample = data.sample(frac=1, replace=True, random_state=state)\n",
    "    values.append(subsample.quantile(0.99))# < write code here >\n",
    "\n",
    "# < write code here >\n",
    "values = pd.Series(values)\n",
    "lower = values.quantile(0.05)# < write code here >\n",
    "upper = values.quantile(0.95)# < write code here >\n",
    "\n",
    "print(values)\n",
    "print(lower)\n",
    "print(upper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a high probability, we can assume that maximum waiting time for 99% of the customers is between 19 and 21 minutes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrap for A/B test analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference between average purchase amounts: 0.7682000000000357\n",
      "p-value = 0.034\n",
      "Reject null hypothesis: average purchase amount is likely to increase\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# data for control group A\n",
    "samples_A = pd.Series([\n",
    "     98.24,  97.77,  95.56,  99.49, 101.4 , 105.35,  95.83,  93.02,\n",
    "    101.37,  95.66,  98.34, 100.75, 104.93,  97.  ,  95.46, 100.03,\n",
    "    102.34,  98.23,  97.05,  97.76,  98.63,  98.82,  99.51,  99.31,\n",
    "     98.58,  96.84,  93.71, 101.38, 100.6 , 103.68, 104.78, 101.51,\n",
    "    100.89, 102.27,  99.87,  94.83,  95.95, 105.2 ,  97.  ,  95.54,\n",
    "     98.38,  99.81, 103.34, 101.14, 102.19,  94.77,  94.74,  99.56,\n",
    "    102.  , 100.95, 102.19, 103.75, 103.65,  95.07, 103.53, 100.42,\n",
    "     98.09,  94.86, 101.47, 103.07, 100.15, 100.32, 100.89, 101.23,\n",
    "     95.95, 103.69, 100.09,  96.28,  96.11,  97.63,  99.45, 100.81,\n",
    "    102.18,  94.92,  98.89, 101.48, 101.29,  94.43, 101.55,  95.85,\n",
    "    100.16,  97.49, 105.17, 104.83, 101.9 , 100.56, 104.91,  94.17,\n",
    "    103.48, 100.55, 102.66, 100.62,  96.93, 102.67, 101.27,  98.56,\n",
    "    102.41, 100.69,  99.67, 100.99])\n",
    "\n",
    "# data for treatment group B\n",
    "samples_B = pd.Series([\n",
    "    101.67, 102.27,  97.01, 103.46, 100.76, 101.19,  99.11,  97.59,\n",
    "    101.01, 101.45,  94.8 , 101.55,  96.38,  99.03, 102.83,  97.32,\n",
    "     98.25,  97.17, 101.1 , 102.57, 104.59, 105.63,  98.93, 103.87,\n",
    "     98.48, 101.14, 102.24,  98.55, 105.61, 100.06,  99.  , 102.53,\n",
    "    101.56, 102.68, 103.26,  96.62,  99.48, 107.6 ,  99.87, 103.58,\n",
    "    105.05, 105.69,  94.52,  99.51,  99.81,  99.44,  97.35, 102.97,\n",
    "     99.77,  99.59, 102.12, 104.29,  98.31,  98.83,  96.83,  99.2 ,\n",
    "     97.88, 102.34, 102.04,  99.88,  99.69, 103.43, 100.71,  92.71,\n",
    "     99.99,  99.39,  99.19,  99.29, 100.34, 101.08, 100.29,  93.83,\n",
    "    103.63,  98.88, 105.36, 101.82, 100.86, 100.75,  99.4 ,  95.37,\n",
    "    107.96,  97.69, 102.17,  99.41,  98.97,  97.96,  98.31,  97.09,\n",
    "    103.92, 100.98, 102.76,  98.24,  97.  ,  98.99, 103.54,  99.72,\n",
    "    101.62, 100.62, 102.79, 104.19])\n",
    "\n",
    "# actual difference between the means in the groups\n",
    "AB_difference = samples_B.mean() - samples_A.mean()# < write code here >\n",
    "print(\"Difference between average purchase amounts:\", AB_difference)\n",
    "\n",
    "alpha = 0.05\n",
    "    \n",
    "state = np.random.RandomState(12345)\n",
    "\n",
    "bootstrap_samples = 1000\n",
    "count = 0\n",
    "for i in range(bootstrap_samples):\n",
    "    # concatenate samples\n",
    "    united_samples = pd.concat([samples_A, samples_B])\n",
    "\n",
    "    # create subsample\n",
    "    subsample = united_samples.sample(frac=1, replace=True, random_state=state)\n",
    "# < write code here >\n",
    "    \n",
    "    # split subsample in half\n",
    "    subsample_A = subsample[:len(samples_A)]# < write code here >\n",
    "    subsample_B = subsample[len(samples_A):]# < write code here >\n",
    "\n",
    "    # find the difference between the means\n",
    "    bootstrap_difference = subsample_B.mean() - subsample_A.mean()# < write code here >\n",
    "    \n",
    "    # if the difference is not less than actual difference, add \"1\" to the counter\n",
    "    if bootstrap_difference >= AB_difference:\n",
    "        count += 1\n",
    "\n",
    "# p-value is equal to the percentage of excess values\n",
    "pvalue = 1. * count / bootstrap_samples\n",
    "print('p-value =', pvalue)\n",
    "\n",
    "if pvalue < alpha:\n",
    "    print(\"Reject null hypothesis: average purchase amount is likely to increase\")\n",
    "else:\n",
    "    print(\"Failed to reject null hypothesis: average purchase amount is unlikely to increase\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrapping for Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def revenue(target, probabilities, count):\n",
    "    # < write code here >\n",
    "    probs_sorted = probabilities.sort_values(ascending=False)\n",
    "    selected = target[probs_sorted.index][:count]\n",
    "    return 10 * selected.sum() # < write code here >\n",
    "\n",
    "target = pd.Series([1,   1,   0,   0,  1,    0])\n",
    "probab = pd.Series([0.2, 0.9, 0.8, 0.3, 0.5, 0.1])\n",
    "\n",
    "res = revenue(target, probab, 3)\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File /datasets/eng_target.csv does not exist: '/datasets/eng_target.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-f2df2f6272c2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# open files\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# take '0' index to convert data to pd.Series\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/datasets/eng_target.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'0'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mprobabilities\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/datasets/eng_probabilites.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'0'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    674\u001b[0m         )\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1112\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1114\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1115\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1891\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File /datasets/eng_target.csv does not exist: '/datasets/eng_target.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# open files\n",
    "# take '0' index to convert data to pd.Series\n",
    "target = pd.read_csv('/datasets/eng_target.csv')['0']\n",
    "probabilities = pd.read_csv('/datasets/eng_probabilites.csv')['0']\n",
    "\n",
    "def revenue(target, probabilities, count):\n",
    "    probs_sorted = probabilities.sort_values(ascending=False)\n",
    "    selected = target[probs_sorted.index][:count]\n",
    "    return 10 * selected.sum()\n",
    "\n",
    "state = np.random.RandomState(12345)\n",
    "    \n",
    "values = []\n",
    "for i in range(1000):\n",
    "    # < write code here>\n",
    "    target_subsample = target.sample(frac=1, replace=True, random_state=state, n=25)\n",
    "    probs_subsample = probabilities[target_subsample.index]\n",
    "    values.append(target_subsample.quantile(0.99))\n",
    "\n",
    "values = pd.Series(values)\n",
    "lower = values.quantile(0.01)# < write code here>\n",
    "\n",
    "mean = values.mean()\n",
    "print(\"Average revenue:\", mean)\n",
    "print(\"1% quantile:\", lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    " \n",
    "# open files\n",
    "# take '0' index to convert data to pd.Series\n",
    "target = pd.read_csv('/datasets/eng_target.csv')['0']\n",
    "probabilities = pd.read_csv('/datasets/eng_probabilites.csv')['0']\n",
    " \n",
    "def revenue(target, probabilities, count):\n",
    "    probs_sorted = probabilities.sort_values(ascending=False)\n",
    "    selected = target[probs_sorted.index][:count]\n",
    "    return 10 * selected.sum()\n",
    " \n",
    "state = np.random.RandomState(12345)\n",
    " \n",
    "values = []\n",
    "for i in range(1000):\n",
    "    subsample = target.sample(n=25, replace=True, random_state=state)\n",
    "    probs_subsample = probabilities[subsample.index]\n",
    "    values.append(revenue(subsample, probs_subsample, 10))\n",
    " \n",
    "\n",
    "values = pd.Series(values)\n",
    "lower = values.quantile(.01)\n",
    " \n",
    "mean = values.mean()\n",
    "print(\"Average revenue:\", mean)\n",
    "print(\"1% quantile:\", lower)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data labeling\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('/datasets/heart_labeled.csv')\n",
    "\n",
    "# < write code h\n",
    "\n",
    "target = []\n",
    "for i in range(data.shape[0]):\n",
    "    labels = data.loc[i, ['label_1', 'label_2', 'label_3']]\n",
    "    # < write code here >]\n",
    "    true_label = labels.mean().round()# < write code here >\n",
    "    target.append(true_label)\n",
    "data['target'] = target\n",
    "\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data labeling\n",
    "import pandas as pd\n",
    "data = pd.read_csv('/datasets/heart_labeled.csv')\n",
    "data['labels'] = data['label_1'] + data['label_2'] + data['label_3']\n",
    "data['target'] =  [1 if x > 1 else 0 for x in data['labels']]\n",
    "del data['labels']\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "data = pd.read_csv('/datasets/heart.csv')\n",
    "features = data.drop(['target'], axis=1)\n",
    "target = data['target']\n",
    "\n",
    "scores = []\n",
    "\n",
    "# set the block size if there are only three of them\n",
    "sample_size = int(len(data)/3)\n",
    "\n",
    "for i in range(0, len(data), sample_size):\n",
    "    valid_indexes = list(range(i, i+len(data)//5))# < write an array of indices for the validation block >\n",
    "    # < write an array of indices for the training set >\n",
    "    train_indexes = list(range(0, i)) + list(range(i+sample_size, len(data)))\n",
    "    \n",
    "# Split variables features and target into samples features_train, target_train, features_valid, target_valid\n",
    "    # < write code here >\n",
    "    features_train = features.iloc[train_indexes]\n",
    "    features_valid = features.iloc[valid_indexes]\n",
    " \n",
    "    target_train = target.iloc[train_indexes]\n",
    "    target_valid = target.iloc[valid_indexes]\n",
    "    \n",
    "    model = DecisionTreeClassifier(random_state=0)\n",
    "    model = model.fit(features_train, target_train)\n",
    "    score = model.score(features_valid, target_valid)# < evaluate model quality >\n",
    "    \n",
    "    scores.append(score)\n",
    " \n",
    "# < calculate average model quality >\n",
    "final_score = np.mean(scores)\n",
    "print('Average model quality score:', final_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(model, features, target, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CV in sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "data = pd.read_csv('/datasets/heart.csv')\n",
    "features = data.drop(['target'], axis=1)\n",
    "target = data['target']\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "# < calculate scores by calling cross_value_score function with five blocks >\n",
    "final_score = np.mean(cross_val_score(model, features, target, cv=5))\n",
    "#final_score = final_score.sum()\n",
    "\n",
    "print('Average model evaluation score:', final_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
