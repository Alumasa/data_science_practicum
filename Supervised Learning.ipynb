{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = pd.read_csv('/datasets/travel_insurance_us.csv')\n",
    "\n",
    "# < write code here >\n",
    "train, valid = train_test_split(data, test_size=0.25, random_state=12345)\n",
    "features_train = train.drop('Claim', axis=1)\n",
    "target_train = train['Claim']\n",
    "features_valid = valid.drop('Claim', axis=1)\n",
    "target_valid = valid['Claim']\n",
    "print(features_train.shape)\n",
    "print(features_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dummy variables\n",
    "print(pd.get_dummies(data['Gender']).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ohe = pd.get_dummies(data, drop_first=True)\n",
    "print(data_ohe.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data_ohe['Claim']\n",
    "features = data_ohe.drop('Claim', axis=1)\n",
    "\n",
    "# < write code here >\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(features, target, test_size=0.25, random_state=12345)\n",
    "model = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "model.fit(features_train, target_train)\n",
    "print(\"Trained!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordinal Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an instance of this class\n",
    "encoder = OrdinalEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-a31c018dd841>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#fit the data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "#fit the data\n",
    "encoder.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform the data\n",
    "data_ordinal = encoder.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add column names\n",
    "data_ordinal = pd.DataFrame(encoder.transform(data), columns=data.columns)\n",
    "\n",
    "#combine fit and transform\n",
    "data_ordinal = pd.DataFrame(encoder.fit_transform(data), columns=data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(random_state=12345)\n",
    "model.fit(features_train, target_train)\n",
    "print(\"Trained!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an instance of the class and tune it using the training data. \n",
    "#The tuning process implies calculating the mean and variance:\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform the training and validation set\n",
    "features_train_scaled = scaler.transform(features_train)\n",
    "features_valid_scaled = scaler.transform(features_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric = ['Duration', 'Net Sales', 'Commission (in value)', 'Age']\n",
    "\n",
    "# < write code here >\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(features_train[numeric])\n",
    "features_train[numeric] = scaler.transform(features_train[numeric])\n",
    "features_valid[numeric] = scaler.transform(features_valid[numeric])\n",
    "#print(features_train[['Duration', 'Net Sales', 'Commission (in value)', 'Age']].head())\n",
    "#print(features_train[numeric].head())\n",
    "print(features_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine categorical feature encoding and numerical feature scaling\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data = pd.read_csv('travel_insurance_us.csv')\n",
    "\n",
    "data_ohe = pd.get_dummies(data, drop_first=True)\n",
    "target = data_ohe['Claim']\n",
    "features = data_ohe.drop('Claim', axis=1)\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(\n",
    "    features, target, test_size=0.25, random_state=12345)\n",
    "\n",
    "numeric = ['Duration', 'Net Sales', 'Commission (in value)', 'Age']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(features_train[numeric])\n",
    "features_train[numeric] = scaler.transform(features_train[numeric])\n",
    "features_valid[numeric] = scaler.transform(features_valid[numeric])\n",
    "\n",
    "print(features_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification  Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy of DecisionTree Classifier\n",
    "model = DecisionTreeClassifier(random_state=12345)\n",
    "model.fit(features_train, target_train)\n",
    "predicted_valid = model.predict(features_valid)\n",
    "accuracy_valid = accuracy_score(predicted_valid, target_valid)\n",
    "print(accuracy_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_frequency = data['Claim'].value_counts(normalize=True)# < write code here >)\n",
    "print(class_frequency)\n",
    "class_frequency.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to make value_counts() work,\n",
    "# we converted results to pd.Series \n",
    "predicted_valid = pd.Series(model.predict(features_valid))\n",
    "\n",
    "# < write code here >\n",
    "class_frequency = predicted_valid.value_counts(normalize=True)\n",
    "print(class_frequency)\n",
    "class_frequency.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a constant model: it predicts class \"0\" for any observation:\n",
    "target_pred_constant = pd.Series(0, index=target.index)\n",
    "\n",
    "print(accuracy_score(target, target_pred_constant))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### True Positive Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "target = pd.Series([1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1])\n",
    "predictions = pd.Series([1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1])\n",
    "((target == 1) & (predictions == 1).values).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### True Negative Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(((target == 0) & (predictions == 0)).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### False Positive Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(((target == 0) & (predictions == 1)).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### False Negative Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(((target == 1) & (predictions == 0)).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "- When TP, FP, TN, FN are collected into a table, it is called a **confusion matrix**.\n",
    "- The confusion matrix allows you to visualize the results of calculating the precision and recall metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 3]\n",
      " [2 5]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(target, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(target_valid, predicted_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall\n",
    "- Recall reveals the portion of positive answers identified by the model\n",
    "- Recall is the share of TP among all answers that have a true label of 1. \n",
    "    - We want the recall value to be close to 1. \n",
    "        - This would mean that the model is good at identifying true positives. \n",
    "            - If it is closer to zero, the model needs to be checked and fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score# < write code here >\n",
    "print(recall_score(target_valid, predicted_valid))# 0.07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7142857142857143\n"
     ]
    }
   ],
   "source": [
    "print(recall_score(target, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision\n",
    "\n",
    "- Another metric for evaluating the quality of a target class prediction is precision.\n",
    "    - Precision measures how many negative answers the model found while searching for positive ones. \n",
    "        - The more negative answers are found, the lower the precision.\n",
    "        - We need the precision to be close to one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score# < write code here >\n",
    "print(precision_score(target_valid. predicted_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.625\n"
     ]
    }
   ],
   "source": [
    "print(precision_score(target,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1 Score\n",
    "- Aggregating metrics — one of which is the F1 score — help to control recall and precision simultaneously. \n",
    "    - This is the harmonic mean of recall and precision. \n",
    "    - In F1, 1 means that the ratio of recall to precision is 1:1.\n",
    "\n",
    "- It's important to understand that when recall or precision is close to zero, the harmonic mean itself approaches 0.\n",
    "\n",
    "*If a positive class is poorly predicted on one of the scales (Recall or Precision), then an F1 score close to zero will show that the prediction of class 1 has failed.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.7142857142857143\n",
      "Precision: 0.625\n",
      "F1 score, F1 is mean: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(target, predictions)# < write code here >\n",
    "recall = recall_score(target, predictions)# < write code here >\n",
    "f1 = (2 * precision * recall) / (precision + recall)# < write code here >\n",
    "\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"F1 score, F1 is mean:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print(f1_score(target_valid, predicted_valid)) # 0.069"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Weights Adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(random_state=12345, solver='liblinear', class_weight='balanced')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "data = pd.read_csv('/datasets/travel_insurance_us_preprocessed.csv')\n",
    "\n",
    "target = data['Claim']\n",
    "features = data.drop('Claim', axis=1)\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(\n",
    "    features, target, test_size=0.25, random_state=12345)\n",
    "\n",
    "def upsample(features, target, repeat):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "    \n",
    "    features_upsampled, target_upsampled = shuffle(\n",
    "        features_upsampled, target_upsampled, random_state=12345)\n",
    "    \n",
    "    return features_upsampled, target_upsampled\n",
    "\n",
    "features_upsampled, target_upsampled = upsample(features_train, target_train, 10)\n",
    "\n",
    "# < write code here >\n",
    "model = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "model.fit(features_upsampled, target_upsampled)\n",
    "predicted_valid = model.predict(features_valid)\n",
    "print(\"F1:\", f1_score(target_valid, predicted_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "data = pd.read_csv('/datasets/travel_insurance_us_preprocessed.csv')\n",
    "\n",
    "target = data['Claim']\n",
    "features = data.drop('Claim', axis=1)\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(\n",
    "    features, target, test_size=0.25, random_state=12345)\n",
    "\n",
    "def downsample(features, target, fraction):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_downsampled = pd.concat(\n",
    "        [features_zeros.sample(frac=fraction, random_state=12345)] + [features_ones])\n",
    "    target_downsampled = pd.concat(\n",
    "        [target_zeros.sample(frac=fraction, random_state=12345)] + [target_ones])\n",
    "    \n",
    "    features_downsampled, target_downsampled = shuffle(\n",
    "        features_downsampled, target_downsampled, random_state=12345)\n",
    "    \n",
    "    return features_downsampled, target_downsampled\n",
    "\n",
    "features_downsampled, target_downsampled = downsample(features_train, target_train, 0.1)\n",
    "\n",
    "# < write code here >\n",
    "model = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "model.fit(features_downsampled, target_downsampled)\n",
    "predicted_valid = model.predict(features_valid)\n",
    "#print(\"F1:\", f1_score(target_valid, predicted_valid))\n",
    "print(\"F1:\", f1_score(target_valid, predicted_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjusting Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities[:, 1]\n",
    "print(probabilities_one_valid[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "data = pd.read_csv('/datasets/travel_insurance_us_preprocessed.csv')\n",
    "\n",
    "target = data['Claim']\n",
    "features = data.drop('Claim', axis=1)\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(\n",
    "    features, target, test_size=0.25, random_state=12345)\n",
    "\n",
    "model = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "model.fit(features_train, target_train)\n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "\n",
    "for threshold in np.arange(0, 0.3, 0.02):\n",
    "    predicted_valid = probabilities_one_valid > threshold# < write code here >\n",
    "    precision = precision_score(target_valid, predicted_valid)# < write code here >\n",
    "    recall = recall_score(target_valid, predicted_valid)# < write code here >\n",
    "\n",
    "    print(\"Threshold = {:.2f} | Precision = {:.3f}, Recall = {:.3f}\".format(\n",
    "        threshold, precision, recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision Recall curve (PR curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "data = pd.read_csv('/datasets/travel_insurance_us_preprocessed.csv')\n",
    "\n",
    "target = data['Claim']\n",
    "features = data.drop('Claim', axis=1)\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(\n",
    "    features, target, test_size=0.25, random_state=12345)\n",
    "\n",
    "model = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "model.fit(features_train, target_train)\n",
    "\n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "precision, recall, thresholds = precision_recall_curve(target_valid, probabilities_valid[:, 1])\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.step(recall, precision, where='post')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC curve\n",
    "Receiver Operating Characteristic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve# < write code here >\n",
    "\n",
    "data = pd.read_csv('/datasets/travel_insurance_us_preprocessed.csv')\n",
    "\n",
    "target = data['Claim']\n",
    "features = data.drop('Claim', axis=1)\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(\n",
    "    features, target, test_size=0.25, random_state=12345)\n",
    "\n",
    "model = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "model.fit(features_train, target_train)\n",
    "\n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(target_valid, probabilities_one_valid)# < write code here >\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "# < plot the graph >\n",
    "plt.plot(fpr, tpr)\n",
    "# ROC curve for random model (looks like a straight line)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "\n",
    "# < use the functions plt.xlim() and plt.ylim() to\n",
    "#   set the boundary for the axes from 0 to 1 >\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 1)\n",
    "# < use the functions plt.xlabel() and plt.ylabel() to\n",
    "#   name the axes \"False Positive Rate\" and \"True Positive Rate\" >\n",
    "plt.xlabel('False Psitive Rate')\n",
    "plt.ylabel('True Positive Rate') \n",
    "# < add the heading \"ROC curve\" with the function plt.title() >\n",
    "plt.title('ROC curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUC-ROC\n",
    "Area Under Curve ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "# < write code here >\n",
    "data = pd.read_csv('/datasets/travel_insurance_us_preprocessed.csv')\n",
    "\n",
    "target = data['Claim']\n",
    "features = data.drop('Claim', axis=1)\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(\n",
    "    features, target, test_size=0.25, random_state=12345)\n",
    "\n",
    "model = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "model.fit(features_train, target_train)\n",
    "\n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "\n",
    "# < write code here >\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "print(auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data preparation\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data = pd.read_csv('/datasets/flights.csv')\n",
    "\n",
    "# < modify data to avoid dummy traps >\n",
    "data_ohe = pd.get_dummies(data, drop_first=True)\n",
    "target = data_ohe['Arrival Delay']\n",
    "features = data_ohe.drop(['Arrival Delay'] , axis=1)\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(\n",
    "    features, target, test_size=0.25, random_state=12345)\n",
    "\n",
    "numeric = ['Day', 'Day Of Week', 'Origin Airport Delay Rate',\n",
    "       'Destination Airport Delay Rate', 'Scheduled Time', 'Distance',\n",
    "       'Scheduled Departure Hour', 'Scheduled Departure Minute']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(features_train[numeric])\n",
    "features_train[numeric] = scaler.transform(features_train[numeric])\n",
    "features_valid[numeric] = scaler.transform(features_valid[numeric])\n",
    "\n",
    "# < transform validation set >\n",
    "\n",
    "print(features_train.shape)\n",
    "print(features_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSE and RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_errormodel = LinearRegression()\n",
    "# < write code here >\n",
    "model.fit(features_train, target_train)\n",
    "predicted_valid = model.predict(features_valid)\n",
    "mse = mean_squared_error(predicted_valid, target_valid)\n",
    "print(\"MSE =\", mse)\n",
    "print(\"RMSE =\", mse ** 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression\n",
      "MSE = 2129.82405285553\n",
      "RMSE = 46.15001682400051\n",
      "Mean\n",
      "MSE = 2358.8874869200226\n",
      "RMSE = 48.568379496540985\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "data = pd.read_csv('datasets/flights_preprocessed.csv')\n",
    "\n",
    "target = data['Arrival Delay']\n",
    "features = data.drop(['Arrival Delay'] , axis=1)\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(\n",
    "    features, target, test_size=0.25, random_state=12345)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(features_train, target_train)\n",
    "predicted_valid = model.predict(features_valid)\n",
    "mse = mean_squared_error(target_valid, predicted_valid)\n",
    "\n",
    "print(\"Linear Regression\")\n",
    "print(\"MSE =\", mse)\n",
    "print(\"RMSE =\", mse ** 0.5)\n",
    "\n",
    "# < write code here >\n",
    "predicted_valid = pd.Series(target_train.mean(), index=target_valid.index)\n",
    "mse = mean_squared_error(target_valid, predicted_valid)\n",
    "print(\"Mean\")\n",
    "print(\"MSE =\", mse)\n",
    "print(\"RMSE =\", mse ** 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coefficient of Determination (R2)\n",
    "\n",
    "The coefficient of determination or the R2 metric (R-squared) divides the Model MSE by the Mean MSE and then subtracts the obtained value from one. \n",
    "- If the metric increases, the model’s quality also improves.\n",
    "- R2 equals one only if the MSE value is zero. Such model would perfectly predict all the answers.\n",
    "- R2 is zero: the model works as well as the mean.\n",
    "- When R2 is negative, the model quality is very low.\n",
    "- R2 can't have values greater than one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 = 0.09710497146204955\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score# < write code here >\n",
    "\n",
    "data = pd.read_csv('datasets/flights_preprocessed.csv')\n",
    "\n",
    "target = data['Arrival Delay']\n",
    "features = data.drop(['Arrival Delay'] , axis=1)\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(\n",
    "    features, target, test_size=0.25, random_state=12345)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(features_train, target_train)\n",
    "predicted_valid = model.predict(features_valid)\n",
    "\n",
    "print(\"R2 =\", r2_score(target_valid, predicted_valid))# < write code here >)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Regressor:\n",
      "Max_depth = 1 : 0.019592666949161508\n",
      "Max_depth = 2 : 0.04708608720463292\n",
      "Max_depth = 3 : 0.07709818999491236\n",
      "Max_depth = 4 : 0.07673458234445973\n",
      "Random Forest Regressor:\n",
      "n_estimators = 10 : 0.14926929882894358\n",
      "n_estimators = 20 : 0.16050981198241898\n",
      "n_estimators = 30 : 0.1623368261875402\n",
      "n_estimators = 40 : 0.16295094390325948\n",
      "n_estimators = 50 : 0.163111041372628\n",
      "n_estimators = 60 : 0.1637813536741587\n",
      "n_estimators = 70 : 0.16372403436837157\n",
      "n_estimators = 80 : 0.16382573576817927\n",
      "n_estimators = 90 : 0.1648855293625755\n",
      "n_estimators = 100 : 0.16455159363220306\n",
      "Linear Regression:\n",
      "0.09710497146204955\n"
     ]
    }
   ],
   "source": [
    "### Code that works on Practicum\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from joblib import dump, load\n",
    "\n",
    "\n",
    "data = pd.read_csv('datasets/flights_preprocessed.csv')\n",
    "\n",
    "target = data['Arrival Delay']\n",
    "features = data.drop(['Arrival Delay'] , axis=1)\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(\n",
    "    features, target, test_size=0.25, random_state=12345)\n",
    "\n",
    "#To test for Decision Tree\n",
    "print(\"Decision Tree Regressor:\")\n",
    "for i in range(1,5):\n",
    "    t_model = DecisionTreeRegressor(random_state = 12345, max_depth = i)\n",
    "    t_model.fit(features_train, target_train)y\n",
    "    t_valid_predictions = t_model.predict(features_valid)\n",
    "    t_r2 = r2_score(target_valid, t_valid_predictions)\n",
    "    #t_rmse = t_mse ** 0.5\n",
    "    print('Max_depth =', i, ':', t_r2)\n",
    " \n",
    "#To test for Random Forest\n",
    "print('Random Forest Regressor:')\n",
    "for i in range(10, 101, 10):\n",
    "    f_model = RandomForestRegressor(n_estimators=i, max_depth=12, random_state=12345)\n",
    "    f_model.fit(features_train, target_train)\n",
    "    f_valid_predictions = f_model.predict(features_valid)\n",
    "    f_r2 = r2_score(target_valid, f_valid_predictions)\n",
    "    #f_rmse = f_mse ** 0.5\n",
    "    print('n_estimators =', i, ':', f_r2)\n",
    " \n",
    "#To test for Linear Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "print('Linear Regression:')\n",
    "l_model = LinearRegression()\n",
    "l_model.fit(features_train, target_train)\n",
    "l_valid_predictions = l_model.predict(features_valid)\n",
    "l_r2 = r2_score(target_valid, l_valid_predictions)\n",
    "#l_rmse = l_mse ** 0.5\n",
    "print(l_r2)\n",
    " \n",
    "#The model with the lowest error is DT with maxx depth of 3.\n",
    "#t3_model = RandomForestRegressor(random_state = 12345, max_depth =10, n_estimators=30)\n",
    "#t3_model.fit(features, target)\n",
    " \n",
    "#dump(t3_model, 'model-5-9.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09710497146204954\n"
     ]
    }
   ],
   "source": [
    "#R2 using score() function\n",
    "model = LinearRegression()\n",
    "model.fit(features_train, target_train)\n",
    "print(model.score(features_valid, target_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.037285907526148354\n",
      "0.06819642209621124\n",
      "0.08784043439422196\n",
      "0.10410539417320942\n",
      "0.1170148926305088\n",
      "0.12812270304109197\n",
      "0.14023988572891255\n",
      "0.1509905046331984\n",
      "0.1561784744742989\n",
      "0.15937461353477067\n",
      "0.16165140416942136\n",
      "0.16050981198241898\n",
      "0.15524848318843387\n",
      "0.14612375630805674\n",
      "0.1419794076464067\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "#number of trees is proprotional to the model quallity.\n",
    "for depth in range(1, 16, 1):\n",
    "    model = RandomForestRegressor(n_estimators=20, max_depth=depth, random_state=12345)\n",
    "    model.fit(features_train, target_train)\n",
    "    print(model.score(features_valid, target_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43399599734071415\n",
      "0.16455159363220306\n"
     ]
    }
   ],
   "source": [
    "#training duration is proportional to a large number of trees\n",
    "model = RandomForestRegressor(n_estimators=100, \n",
    "    max_depth=12, random_state=12345)\n",
    "model.fit(features_train, target_train)\n",
    "print(model.score(features_train, target_train))\n",
    "print(model.score(features_valid, target_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 45.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
       "                      random_state=12345, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cell execution time\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=12345)\n",
    "%time model.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Absolute Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17500000000000004\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def mae(target, predictions):\n",
    "    error = 0\n",
    "    for i in range(target.shape[0]):\n",
    "        error += abs(target[i] - predictions[i])\n",
    "    return error / target.shape[0]\n",
    "\n",
    "target = pd.Series([-0.5, 2.1, 1.5, 0.3])\n",
    "predictions = pd.Series([-0.6, 1.7, 1.6, 0.2])\n",
    "\n",
    "print(mae(target, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(target, predictions):\n",
    "    error = 0\n",
    "    for i in range(target.shape[0]):\n",
    "        error += abs(target[i] - predictions[i])\n",
    "    return error / target.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.436250978085837\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# < write code here >\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "data = pd.read_csv('datasets/flights_preprocessed.csv')\n",
    "\n",
    "target = data['Arrival Delay']\n",
    "features = data.drop(['Arrival Delay'] , axis=1)\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(\n",
    "    features, target, test_size=0.25, random_state=12345)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(features_train, target_train)\n",
    "predicted_valid = model.predict(features_valid)\n",
    "\n",
    "print(mean_absolute_error(target_valid, predicted_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The mean error for each observation is 27 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression\n",
      "27.436250978085837\n",
      "\n",
      "Median\n",
      "27.22281548413595\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "data = pd.read_csv('datasets/flights_preprocessed.csv')\n",
    "\n",
    "target = data['Arrival Delay']\n",
    "features = data.drop(['Arrival Delay'] , axis=1)\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(\n",
    "    features, target, test_size=0.25, random_state=12345)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(features_train, target_train)\n",
    "predicted_valid = model.predict(features_valid)\n",
    "\n",
    "print(\"Linear Regression\")\n",
    "print(mean_absolute_error(target_valid, predicted_valid))\n",
    "print()\n",
    "\n",
    "predicted_valid = predicted_valid = pd.Series(target_train.median(), index=target_valid.index)\n",
    "print(\"Median\")\n",
    "print(mean_absolute_error(target_valid, predicted_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
